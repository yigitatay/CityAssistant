{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import textstat\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "questions_df = pd.read_csv('./data/resident_request_questions.csv')\n",
    "context_df = pd.read_csv('./data/dc_service_requests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    return np.array(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_type</th>\n",
       "      <th>department</th>\n",
       "      <th>resolution_estimate</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abandoned Bicycle</td>\n",
       "      <td>DPW, DPW</td>\n",
       "      <td>20 bd</td>\n",
       "      <td>This service request is to be used for bicycle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abandoned Vehicle - On Private Property</td>\n",
       "      <td>DPW, DPW</td>\n",
       "      <td>45 bd</td>\n",
       "      <td>Please use this service request to request the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abandoned Vehicle - On Public Property</td>\n",
       "      <td>DPW, DPW</td>\n",
       "      <td>13 bd</td>\n",
       "      <td>Please use this service request to request the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alley Repair Investigation</td>\n",
       "      <td>DDOT</td>\n",
       "      <td>270 bd</td>\n",
       "      <td>Please use this service request type to invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bee Treatment and Inspection (DOH)</td>\n",
       "      <td>DOH</td>\n",
       "      <td>14 bd</td>\n",
       "      <td>Bee Treatment - This service request is limite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Tree Inspection</td>\n",
       "      <td>DDOT</td>\n",
       "      <td>5 bd</td>\n",
       "      <td>Use this request type to report an urgent tree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Tree Planting</td>\n",
       "      <td>DDOT</td>\n",
       "      <td>500 bd</td>\n",
       "      <td>Urban Forestry Administration (UFA) plants nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Tree Pruning</td>\n",
       "      <td>DDOT</td>\n",
       "      <td>180 bd</td>\n",
       "      <td>Please use this service type to request a publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Tree Removal</td>\n",
       "      <td>DDOT</td>\n",
       "      <td>180 bd</td>\n",
       "      <td>Please use this service type to request the re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Vacant Lot - Public Property Only</td>\n",
       "      <td>DPW</td>\n",
       "      <td>50 bd</td>\n",
       "      <td>Please use this service request type to reques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               request_type department resolution_estimate  \\\n",
       "0                         Abandoned Bicycle   DPW, DPW               20 bd   \n",
       "1   Abandoned Vehicle - On Private Property   DPW, DPW               45 bd   \n",
       "2    Abandoned Vehicle - On Public Property   DPW, DPW               13 bd   \n",
       "3                Alley Repair Investigation       DDOT              270 bd   \n",
       "4        Bee Treatment and Inspection (DOH)        DOH               14 bd   \n",
       "..                                      ...        ...                 ...   \n",
       "82                          Tree Inspection       DDOT                5 bd   \n",
       "83                            Tree Planting       DDOT              500 bd   \n",
       "84                             Tree Pruning       DDOT              180 bd   \n",
       "85                             Tree Removal       DDOT              180 bd   \n",
       "86        Vacant Lot - Public Property Only        DPW               50 bd   \n",
       "\n",
       "                                          Description  \n",
       "0   This service request is to be used for bicycle...  \n",
       "1   Please use this service request to request the...  \n",
       "2   Please use this service request to request the...  \n",
       "3   Please use this service request type to invest...  \n",
       "4   Bee Treatment - This service request is limite...  \n",
       "..                                                ...  \n",
       "82  Use this request type to report an urgent tree...  \n",
       "83  Urban Forestry Administration (UFA) plants nea...  \n",
       "84  Please use this service type to request a publ...  \n",
       "85  Please use this service type to request the re...  \n",
       "86  Please use this service request type to reques...  \n",
       "\n",
       "[87 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(context_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_estimate_helper(res_estimate):\n",
    "    resolution_estimate = res_estimate.split(' ')[0]\n",
    "    bd_or_cd = res_estimate.split(' ')[1]\n",
    "    resolution_estimate += ' business days' if bd_or_cd == 'bd' else ' calendar days'\n",
    "    return resolution_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []\n",
    "\n",
    "for idx, row in context_df.iterrows():\n",
    "    combined_text = (\n",
    "        f\"Request Type: {row['request_type']}\\n\"\n",
    "        f\"Department: {row['department']}\\n\"\n",
    "        f\"Resolution Estimate: {res_estimate_helper(row['resolution_estimate'])}\\n\"\n",
    "        f\"Description: {row['Description']}\"\n",
    "    )\n",
    "    \n",
    "    embed_vec = get_embedding(combined_text)\n",
    "    all_embeddings.append(embed_vec)\n",
    "\n",
    "all_embeddings = np.array(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = all_embeddings.astype(np.float32)\n",
    "embedding_dim = all_embeddings.shape[1]\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
    "faiss_index.add(all_embeddings)\n",
    "faiss.write_index(faiss_index, \"./faiss/dc_requests.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To simply load pre-calculated, run this:\n",
    "faiss_index = faiss.read_index(\"./faiss/dc_requests.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_dc_requests(query: str, top_k: int = 3):\n",
    "    query_vec = get_embedding(query).astype(np.float32).reshape(1, -1)\n",
    "    # Search FAISS index\n",
    "    distances, indices = faiss_index.search(query_vec, top_k)\n",
    "\n",
    "    results = []\n",
    "    for rank, idx in enumerate(indices[0]):\n",
    "        row_data = context_df.iloc[idx]\n",
    "        dist = distances[0][rank]\n",
    "        results.append({\n",
    "            \"request_type\": row_data[\"request_type\"],\n",
    "            \"department\": row_data[\"department\"],\n",
    "            \"resolution_estimate\": res_estimate_helper(row_data[\"resolution_estimate\"]),\n",
    "            \"description\": row_data[\"Description\"],\n",
    "            \"distance\": float(dist),\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'request_type': 'Pothole', 'department': 'DDOT', 'resolution_estimate': '3 business days', 'description': 'Please use this request type for Pothole investigation. Pothole repairs normally take approximately 3 business days (72 hours), weather permitting, for completion.\\n\\n', 'distance': 0.23399491608142853}, {'request_type': 'Roadway Repair', 'department': 'DDOT', 'resolution_estimate': '270 business days', 'description': 'Please use this service request type to investigate street surface issues. Please provide the specific location (i.e. address, intersection) and describe the specific repair problem (i.e. uneven pavement, numerous potholes). Also if possible, provide any information regarding the street surfaces paving material (i.e. concrete, asphalt, or brick).\\n\\n', 'distance': 0.3189466595649719}, {'request_type': 'Alley Repair Investigation', 'department': 'DDOT', 'resolution_estimate': '270 business days', 'description': 'Please use this service request type to investigate alley surfaces issues. Please identify the specific alley location, provide a description of problem (i.e. pothole, re-paving) and describe the type of existing alley surface (i.e. dirt, concrete, brick). It is also helpful to provide any additional information specific to the proposed repair.', 'distance': 0.32842686772346497}]\n"
     ]
    }
   ],
   "source": [
    "query = \"How long does it take to fix a pothole?\"\n",
    "dc_matches = search_dc_requests(query, top_k=3)\n",
    "print(dc_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_query):\n",
    "    # 1. Retrieve relevant requests from context\n",
    "    dc_results = search_dc_requests(user_query, top_k=3)\n",
    "    \n",
    "    # 2. Create context string\n",
    "    context_lines = []\n",
    "    for res in dc_results:\n",
    "        context_lines.append(\n",
    "            f\"Request Type: {res['request_type']}\\n\"\n",
    "            f\"Department: {res['department']}\\n\"\n",
    "            f\"Resolution Estimate: {res['resolution_estimate']}\\n\"\n",
    "            f\"Description: {res['description']}\\n\"\n",
    "            f\"Distance: {res['distance']}\\n\"\n",
    "            \"----\"\n",
    "        )\n",
    "    context_str = \"\\n\".join(context_lines)\n",
    "    \n",
    "    # 3. Build the final prompt\n",
    "    SYSTEM_PROMPT = \"You are a QA system that assists with resident inquiries and service requests in Washington D.C.\"\n",
    "    FINAL_PROMPT = (\n",
    "        f\"{SYSTEM_PROMPT}\\n\\n\"\n",
    "        f\"Context from Washington D.C. service requests:\\n{context_str}\\n\\n\"\n",
    "        f\"User's question: {user_query}\\n\"\n",
    "        f\"Provide clear, concise, and legally compliant responses.\"\n",
    "        f\"Make sure your response is easily readable and understandable by a layman.\" \n",
    "        f\"If the answer doesn't belong to one of the request types, state that you're not sure.\"\n",
    "        f\"Answer format:\"\n",
    "        f\"- The content of your answer\"\n",
    "        f\"- Used request type: The request type you used\"\n",
    "    )\n",
    "    \n",
    "    # 4. Call API\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": FINAL_PROMPT},\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_completeness(ai_response, required_fields):\n",
    "    \"\"\"\n",
    "    A naive completeness check that ensures the AI response mentions \n",
    "    certain keywords or phrases. 'required_fields' can be a list of items \n",
    "    we expect to see in the answer (e.g., department, resolution, etc.).\n",
    "\n",
    "    Returns True if all required fields appear, otherwise False.\n",
    "    \"\"\"\n",
    "    response_lower = ai_response.lower()\n",
    "    for field in required_fields:\n",
    "        if field.lower() not in response_lower:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprompt_for_correctness(query, ai_response, context_info):\n",
    "    \"\"\"\n",
    "    Calls the LLM again to check whether the AI's answer is correct \n",
    "    given the context_info (e.g., the row from dc_service_requests).\n",
    "    Returns a dict with \"is_correct\" and \"revised_answer\" or similar fields.\n",
    "    \n",
    "    For demonstration, we do a ChatCompletion call that we parse.\n",
    "    In production, you might want more robust JSON parsing or error handling.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"You are a QA system verifying correctness of the AIâ€™s response.\"\n",
    "    user_prompt = f\"\"\"\n",
    "User Query: {query}\n",
    "\n",
    "AI Response:\n",
    "{ai_response.split('Used request type:')[0]}\n",
    "\n",
    "Relevant Context (from official data):\n",
    "{context_info}\n",
    "\n",
    "Task:\n",
    "1. Check if the AI's response is factually correct and consistent with the context.\n",
    "2. If incorrect or incomplete, propose a corrected version.\n",
    "3. Return your findings in the following JSON format:\n",
    "{{\n",
    "  \"is_correct\": true or false,\n",
    "  \"revised_answer\": \"text\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Attempt to parse a JSON-like structure from the content\n",
    "    # We'll do a simple regex to find a JSON block, then use Python's `json` if well-formed\n",
    "    try:\n",
    "        # find a JSON substring\n",
    "        json_match = re.search(r\"\\{.*\\}\", content, flags=re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "            parsed = json.loads(json_str)\n",
    "            return parsed\n",
    "        else:\n",
    "            return {\n",
    "                \"is_correct\": False,\n",
    "                \"revised_answer\": \"Could not parse JSON from LLM response\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"is_correct\": False,\n",
    "            \"revised_answer\": f\"Error parsing LLM output: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response_with_rules(query, ai_response, request_type):\n",
    "    \"\"\"\n",
    "    Checks if the AI response obeys known rules from context_df and overall readability guidelines.\n",
    "    Returns a dictionary with flags, metrics, and/or suggested corrections.\n",
    "    \"\"\"\n",
    "    evaluation_result = {\n",
    "        \"flesch_reading_ease\": None, \n",
    "        \"gunning_fog\": None,\n",
    "        \"potential_request_types\": None,\n",
    "        \"rt_complete\": True,\n",
    "        \"resolution_estimate_complete\": True,\n",
    "        \"complete\": True\n",
    "    }\n",
    "\n",
    "    # 1. Check readability\n",
    "    evaluation_result['flesch_reading_ease'] = textstat.flesch_reading_ease(ai_response)\n",
    "    evaluation_result['gunning_fog'] = textstat.gunning_fog(ai_response)\n",
    "    \n",
    "    # 2. Check if request type is in the context\n",
    "    search_matches = search_dc_requests(query, top_k=3)\n",
    "    potential_request_types = [match['request_type'].lower() for match in search_matches]\n",
    "    if request_type.lower() not in potential_request_types:\n",
    "        evaluation_result.update({\"rt_complete\": False, \"resolution_estimate_complete\": False, \"complete\": False})\n",
    "        index_of_req = -1\n",
    "    else:\n",
    "        index_of_req = potential_request_types.index(request_type.lower())\n",
    "\n",
    "    evaluation_result[\"potential_request_types\"] = potential_request_types\n",
    "\n",
    "    # 3. Check if the estimated resolution time is stated in the answer\n",
    "    known_resolution_estimates = []\n",
    "    for elem in search_matches:\n",
    "        known_resolution_estimates.append(elem[\"resolution_estimate\"])\n",
    "    \n",
    "    if index_of_req > -1:\n",
    "        ai_resolution_estimate = known_resolution_estimates[index_of_req]\n",
    "        ai_resolution_days = ai_resolution_estimate.split(' ')[0]\n",
    "        if (ai_resolution_days not in ai_response or \n",
    "        (ai_resolution_days == '1' and not any(x in ai_response for x in ['1', 'one']))):\n",
    "            evaluation_result.update({\"resolution_estimate_complete\": False, \"complete\": False})\n",
    "    \n",
    "\n",
    "    # 4. Re-Prompt to Check Correctness\n",
    "    context_lines = []\n",
    "    for res in search_matches:\n",
    "        context_lines.append(\n",
    "            f\"Request Type: {res['request_type']}\\n\"\n",
    "            f\"Department: {res['department']}\\n\"\n",
    "            f\"Resolution Estimate: {res['resolution_estimate']}\\n\"\n",
    "            f\"Description: {res['description']}\\n\"\n",
    "            f\"Distance: {res['distance']}\\n\"\n",
    "            \"----\"\n",
    "        )\n",
    "    context_str = \"\\n\".join(context_lines)\n",
    "    correctness_check = reprompt_for_correctness(query, ai_response, context_str)\n",
    "    \n",
    "    evaluation_result[\"is_correct\"] = correctness_check.get(\"is_correct\")\n",
    "    evaluation_result[\"revised_answer\"] = correctness_check.get(\"revised_answer\")\n",
    "\n",
    "    return evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: Do I need a permit to build a fence around my yard?\n",
      "AI Answer: You may need a permit to build a fence around your yard in Washington D.C. It is advisable to contact the Department of Consumer and Regulatory Affairs (DCRA) to inquire about the specific requirements for building a fence on your property. They can provide guidance on whether a permit is necessary based on the height and location of the fence.\n",
      "\n",
      "Used request type: Not sure\n",
      "\n",
      "EVALUATION OF AI RESPONSE:\n",
      "\n",
      "READABILITY:\n",
      "Flesch reading ease score: 54.93\n",
      "Gunning fog index: 12.67\n",
      "\n",
      "Potential request types: ['dob - illegal construction', 'residential parking permit violation', 'resident parking permit']\n",
      "\n",
      "COMPLETENESS:\n",
      "Flagged Response: The AI response is not complete.\n",
      "The response does not include the estimated time for resolution of the request.\n",
      "The response does not state which request type the request belongs to. The question might not be in the context.\n",
      "\n",
      "CORRECTNESS:\n",
      "AI response seems to be correct.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Do I need a permit to build a fence around my yard?\"\n",
    "# user_query = \"I started seeing lots of dead rats on my street. What can I do about this?\"\n",
    "# user_query = \"There is always trash left in front of my building. What can I do about this?\"\n",
    "\n",
    "ai_answer = generate_response(user_query)\n",
    "try:\n",
    "    request_type = ai_answer.split(\"Used request type: \")[1]\n",
    "except:\n",
    "    request_type = 'Not found'\n",
    "\n",
    "eval_result = evaluate_response_with_rules(user_query, ai_answer, request_type)\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Answer:\", ai_answer)\n",
    "print(\"\\nEVALUATION OF AI RESPONSE:\\n\")\n",
    "\n",
    "print(\"READABILITY:\")\n",
    "print(f\"Flesch reading ease score: {eval_result['flesch_reading_ease']}\")\n",
    "print(f\"Gunning fog index: {eval_result['gunning_fog']}\")\n",
    "\n",
    "print(f\"\\nPotential request types: {eval_result['potential_request_types']}\")\n",
    "\n",
    "print(\"\\nCOMPLETENESS:\")\n",
    "if not eval_result[\"complete\"]:\n",
    "    print(\"Flagged Response: The AI response is not complete.\")\n",
    "    if not eval_result['resolution_estimate_complete']:\n",
    "        print(\"The response does not include the estimated time for resolution of the request.\")\n",
    "    if not eval_result['rt_complete']:\n",
    "        print(\"The response does not state which request type the request belongs to. The question might not be in the context.\")\n",
    "else:\n",
    "    print('AI response is complete.')\n",
    "\n",
    "print(\"\\nCORRECTNESS:\")\n",
    "if not eval_result['is_correct']:\n",
    "    print(\"The answer might not be correct. Here's the revised response:\")\n",
    "    print(eval_result['revised_answer'])\n",
    "else:\n",
    "    print('AI response seems to be correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's run the model and evaluation on the simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/frp599y55cd4g88r9btj2j8r0000gn/T/ipykernel_9095/3462507888.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, dict_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ai_response</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>rt_complete</th>\n",
       "      <th>re_complete</th>\n",
       "      <th>complete</th>\n",
       "      <th>correct</th>\n",
       "      <th>revised_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How quickly can the city respond to a request ...</td>\n",
       "      <td>The city can respond to a request for insect t...</td>\n",
       "      <td>68.77</td>\n",
       "      <td>6.22</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of insects are typically treated by ...</td>\n",
       "      <td>The city typically treats bees and rodents as ...</td>\n",
       "      <td>57.77</td>\n",
       "      <td>9.84</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a limit on the number of times a resi...</td>\n",
       "      <td>Residents in Washington D.C. can request insec...</td>\n",
       "      <td>57.47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How long will it take to receive a new trash c...</td>\n",
       "      <td>It will take approximately 20 business days to...</td>\n",
       "      <td>50.33</td>\n",
       "      <td>9.80</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is there a limit to the number of trash carts ...</td>\n",
       "      <td>There is no specific limit mentioned in the se...</td>\n",
       "      <td>44.34</td>\n",
       "      <td>15.62</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>How can I report a serious medication error th...</td>\n",
       "      <td>To report a serious medication error that you ...</td>\n",
       "      <td>21.70</td>\n",
       "      <td>14.79</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>What are the potential consequences of a serio...</td>\n",
       "      <td>I'm not sure which request type this question ...</td>\n",
       "      <td>86.71</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The AI response is not relevant to the user qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>How can I request a modification to the roadwa...</td>\n",
       "      <td>To request a modification to the roadway marki...</td>\n",
       "      <td>48.09</td>\n",
       "      <td>8.61</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>What is the process for reviewing and approvin...</td>\n",
       "      <td>The process for reviewing and approving roadwa...</td>\n",
       "      <td>37.40</td>\n",
       "      <td>12.91</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Can I propose specific changes to the roadway ...</td>\n",
       "      <td>Yes, you can propose specific changes to roadw...</td>\n",
       "      <td>44.75</td>\n",
       "      <td>12.76</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    How quickly can the city respond to a request ...   \n",
       "1    What type of insects are typically treated by ...   \n",
       "2    Is there a limit on the number of times a resi...   \n",
       "3    How long will it take to receive a new trash c...   \n",
       "4    Is there a limit to the number of trash carts ...   \n",
       "..                                                 ...   \n",
       "352  How can I report a serious medication error th...   \n",
       "353  What are the potential consequences of a serio...   \n",
       "354  How can I request a modification to the roadwa...   \n",
       "355  What is the process for reviewing and approvin...   \n",
       "356  Can I propose specific changes to the roadway ...   \n",
       "\n",
       "                                           ai_response  flesch_reading_ease  \\\n",
       "0    The city can respond to a request for insect t...                68.77   \n",
       "1    The city typically treats bees and rodents as ...                57.77   \n",
       "2    Residents in Washington D.C. can request insec...                57.47   \n",
       "3    It will take approximately 20 business days to...                50.33   \n",
       "4    There is no specific limit mentioned in the se...                44.34   \n",
       "..                                                 ...                  ...   \n",
       "352  To report a serious medication error that you ...                21.70   \n",
       "353  I'm not sure which request type this question ...                86.71   \n",
       "354  To request a modification to the roadway marki...                48.09   \n",
       "355  The process for reviewing and approving roadwa...                37.40   \n",
       "356  Yes, you can propose specific changes to roadw...                44.75   \n",
       "\n",
       "     gunning_fog rt_complete re_complete complete correct  \\\n",
       "0           6.22        True        True     True    True   \n",
       "1           9.84       False       False    False    True   \n",
       "2          10.61        True       False    False    True   \n",
       "3           9.80        True        True     True    True   \n",
       "4          15.62        True       False    False    True   \n",
       "..           ...         ...         ...      ...     ...   \n",
       "352        14.79       False       False    False    True   \n",
       "353         4.00       False       False    False   False   \n",
       "354         8.61        True        True     True    True   \n",
       "355        12.91        True        True     True    True   \n",
       "356        12.76        True       False    False    True   \n",
       "\n",
       "                                        revised_answer  \n",
       "0                                              Correct  \n",
       "1                                              Correct  \n",
       "2                                              Correct  \n",
       "3                                              Correct  \n",
       "4                                              Correct  \n",
       "..                                                 ...  \n",
       "352                                            Correct  \n",
       "353  The AI response is not relevant to the user qu...  \n",
       "354                                            Correct  \n",
       "355                                            Correct  \n",
       "356                                            Correct  \n",
       "\n",
       "[357 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resident_questions = list(questions_df['question'])\n",
    "results_df = pd.DataFrame(columns=['question', 'ai_response', 'flesch_reading_ease', 'gunning_fog', 'rt_complete', 're_complete', 'complete', 'correct', 'revised_answer'])\n",
    "\n",
    "for i, question in enumerate(resident_questions):\n",
    "    cur_dict = {}\n",
    "    ai_answer = generate_response(question)\n",
    "    try:\n",
    "        request_type = ai_answer.split(\"Used request type: \")[1]\n",
    "    except:\n",
    "        request_type = 'Not found'\n",
    "\n",
    "    eval_result = evaluate_response_with_rules(question, ai_answer, request_type)\n",
    "\n",
    "    flesch_re, gunning_fog = eval_result['flesch_reading_ease'], eval_result['gunning_fog']\n",
    "    rt_complete, re_complete, complete = eval_result['rt_complete'], eval_result['resolution_estimate_complete'], eval_result['complete']\n",
    "    correct = eval_result['is_correct']\n",
    "    revised_answer = eval_result['revised_answer'] if not correct else 'Correct'\n",
    "\n",
    "    cur_dict = {\n",
    "        'question': question,\n",
    "        'ai_response': ai_answer,\n",
    "        'flesch_reading_ease': flesch_re,\n",
    "        'gunning_fog': gunning_fog,\n",
    "        'rt_complete': rt_complete,\n",
    "        're_complete': re_complete,\n",
    "        'complete': complete,\n",
    "        'correct': correct,\n",
    "        'revised_answer': revised_answer\n",
    "    }\n",
    "    dict_df = pd.DataFrame([cur_dict])\n",
    "\n",
    "    results_df = pd.concat([results_df, dict_df], ignore_index=True)\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('./data/resident_request_ai_answers.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.71871148459384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv('./data/resident_request_ai_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_mean = np.mean(results_df['flesch_reading_ease'])\n",
    "gunning_fog_mean = np.mean(results_df['gunning_fog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regarding the readability of the responses, the mean flesch reading ease score is: 42.719, and the mean gunning fog value is: 12.72.\n",
      "\n",
      "Based on re-prompting the AI responses, the percentage of correct responses is: 92.997%\n",
      "\n",
      "The percentage of complete responses is: 27.171%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Regarding the readability of the responses, the mean flesch reading ease score is: {round(fre_mean, 3)}, and the mean gunning fog value is: {round(gunning_fog_mean, 3)}.\")\n",
    "\n",
    "total_count = results_df.shape[0]\n",
    "\n",
    "correct_count = results_df.correct.sum()\n",
    "perc_correct = correct_count / total_count * 100.0\n",
    "print(f\"\\nBased on re-prompting the AI responses, the percentage of correct responses is: {round(perc_correct, 3)}%\")\n",
    "\n",
    "complete_count = results_df.complete.sum()\n",
    "perc_complete = complete_count / total_count * 100.0\n",
    "print(f\"\\nThe percentage of complete responses is: {round(perc_complete, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
